{
    "full_executed": true,
    "hnn_version": "0.4.2",
    "parallelism_joblib_notebook.ipynb": {
        "7.7: Parallelism: Using the Joblib backend": {
            "level": 1,
            "html": "<div class='markdown-cell'>\n    <h1>7.7: Parallelism: Using the Joblib backend</h1>\n<p>This example demonstrates how to use the Joblib backend for\nsimulating dipoles using <code>hnn_core</code>.</p>\n<p><code>hnn_core</code> can take advantage of <a\nhref=\"https://joblib.readthedocs.io/en/stable/\">the Joblib library</a>\nto run <strong>multiple</strong> independent simulations simultaneously\nacross <strong>multiple</strong> CPU processors. This is an example of\n<a\nhref=\"https://en.wikipedia.org/wiki/Embarrassingly_parallel\">\"embarrassingly\nparallel\" processing jobs</a>. In HNN, this is commonly done if you want\nto run many \"trials\" of the same simulation. Since each trial simulation\nis fully independent of the other trial simulations, each trial\nsimulation can be run on its own CPU core. Joblib parallelism is\nparticularly useful if you are using <a\nhref=\"https://jonescompneurolab.github.io/textbook/content/08_using_hnn_api/batch_simulation.html\">batch\nsimulation to explore parameter spaces</a>.</p>\n<p>Note that to use Joblib parallelism, you need either the\n<code>conda</code> install or the <code>pip</code>\n<code>Joblib Installation</code> dependencies described <a\nhref=\"https://jonescompneurolab.github.io/textbook/content/01_getting_started/installation.html\">in\nour Installation Guide here</a>.</p>\n<p>Note that Joblib parallelism is distinct from <code>hnn_core</code>'s\nuse of <a\nhref=\"https://jonescompneurolab.github.io/textbook/content/08_using_hnn_api/parallelism_mpi.html\">MPI\nparallelism, which can be found here</a>.</p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        # Authors: Mainak Jas <mjas@mgh.harvard.edu>\n#          Blake Caldwell <blake_caldwell@brown.edu>\n#          Austin Soplata <austin_soplata@brown.edu>\n    </code>\n</div>\n<div class='markdown-cell'>\n    <p>Let us import what we need from <code>hnn_core</code>:</p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        import matplotlib.pyplot as plt\n\nfrom hnn_core import simulate_dipole, jones_2009_model\nfrom hnn_core.viz import plot_dipole\n    </code>\n</div>\n<div class='markdown-cell'>\n    <p>Following our <a\nhref=\"https://jonescompneurolab.github.io/textbook/content/06_alpha_beta/api.html\">Alpha\nexample</a>, we will create our network and add a ~10 Hz \"bursty\"\ndrive:</p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        net = jones_2009_model()\n\nweights_ampa = {'L2_pyramidal': 5.4e-5, 'L5_pyramidal': 5.4e-5}\nnet.add_bursty_drive(\n    'bursty', tstart=50., burst_rate=10, burst_std=20., numspikes=2,\n    spike_isi=10, n_drive_cells=10, location='distal',\n    weights_ampa=weights_ampa, event_seed=278)\n    </code>\n</div>\n<div class='markdown-cell'>\n    <p>Finally, we will simulate using the <a\nhref=\"https://jonescompneurolab.github.io/hnn-core/dev/generated/hnn_core.parallel_backends.JoblibBackend.html#hnn_core.parallel_backends.JoblibBackend\"><code>JoblibBackend</code>\nclass</a>. You can control the number of CPU cores to use via\n<code>n_jobs</code>, while the number of total trials to be run can be\nspecified by <code>n_trials</code>. Note that these numbers do NOT have\nto match: you can ask for more trials than there are jobs available, and\nJoblib will simply execute later jobs after the first batch has\ncompleted.</p>\n\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        from hnn_core import JoblibBackend\n\nwith JoblibBackend(n_jobs=4):\n    dpls = simulate_dipole(net, tstop=210., n_trials=6)\n    </code>\n</div>\n<div class='output-cell'><div class='output-label'>\n    Out:\n</div>\n    <div class='output-code'>\n        Joblib will run 6 trial(s) in parallel by distributing trials over 4 jobs.\n\n        Loading custom mechanism files from /usr/share/miniconda/envs/textbook-env-mpi/lib/python3.12/site-packages/hnn_core/mod/x86_64/libnrnmech.so\nBuilding the NEURON model\nLoading custom mechanism files from /usr/share/miniconda/envs/textbook-env-mpi/lib/python3.12/site-packages/hnn_core/mod/x86_64/libnrnmech.so\nBuilding the NEURON model\nLoading custom mechanism files from /usr/share/miniconda/envs/textbook-env-mpi/lib/python3.12/site-packages/hnn_core/mod/x86_64/libnrnmech.so\nBuilding the NEURON model\nLoading custom mechanism files from /usr/share/miniconda/envs/textbook-env-mpi/lib/python3.12/site-packages/hnn_core/mod/x86_64/libnrnmech.so\nBuilding the NEURON model\n\n        [Done]\n[Done]\nTrial 1: 0.03 ms...\nTrial 4: 0.03 ms...\n[Done]\n[Done]\nTrial 2: 0.03 ms...\nTrial 3: 0.03 ms...\n\n        Trial 1: 10.0 ms...\nTrial 4: 10.0 ms...\nTrial 2: 10.0 ms...\n\n        Trial 3: 10.0 ms...\n\n        Trial 1: 20.0 ms...\nTrial 4: 20.0 ms...\nTrial 2: 20.0 ms...\n\n        Trial 3: 20.0 ms...\n\n        Trial 1: 30.0 ms...\nTrial 4: 30.0 ms...\nTrial 2: 30.0 ms...\n\n        Trial 3: 30.0 ms...\n\n        Trial 1: 40.0 ms...\nTrial 2: 40.0 ms...\nTrial 4: 40.0 ms...\nTrial 3: 40.0 ms...\n\n        Trial 2: 50.0 ms...\nTrial 1: 50.0 ms...\nTrial 4: 50.0 ms...\nTrial 3: 50.0 ms...\n\n        Trial 2: 60.0 ms...\nTrial 1: 60.0 ms...\nTrial 4: 60.0 ms...\nTrial 3: 60.0 ms...\n\n        Trial 2: 70.0 ms...\nTrial 3: 70.0 ms...\nTrial 1: 70.0 ms...\n\n        Trial 4: 70.0 ms...\n\n        Trial 2: 80.0 ms...\nTrial 3: 80.0 ms...\n\n        Trial 1: 80.0 ms...\nTrial 4: 80.0 ms...\n\n        Trial 2: 90.0 ms...\nTrial 3: 90.0 ms...\n\n        Trial 1: 90.0 ms...\nTrial 4: 90.0 ms...\n\n        Trial 2: 100.0 ms...\nTrial 3: 100.0 ms...\n\n        Trial 1: 100.0 ms...\nTrial 4: 100.0 ms...\n\n        Trial 2: 110.0 ms...\nTrial 3: 110.0 ms...\n\n        Trial 1: 110.0 ms...\nTrial 4: 110.0 ms...\n\n        Trial 2: 120.0 ms...\nTrial 3: 120.0 ms...\n\n        Trial 1: 120.0 ms...Trial 4: 120.0 ms...\n\n\n        Trial 2: 130.0 ms...\nTrial 3: 130.0 ms...\n\n        Trial 1: 130.0 ms...Trial 4: 130.0 ms...\n\n\n        Trial 2: 140.0 ms...\nTrial 3: 140.0 ms...\n\n        Trial 4: 140.0 ms...\nTrial 1: 140.0 ms...\n\n        Trial 2: 150.0 ms...\nTrial 3: 150.0 ms...\n\n        Trial 4: 150.0 ms...\nTrial 1: 150.0 ms...\n\n        Trial 2: 160.0 ms...\nTrial 3: 160.0 ms...\n\n        Trial 4: 160.0 ms...\nTrial 1: 160.0 ms...\n\n        Trial 2: 170.0 ms...\nTrial 3: 170.0 ms...\n\n        Trial 4: 170.0 ms...\nTrial 1: 170.0 ms...\n\n        Trial 2: 180.0 ms...\nTrial 3: 180.0 ms...\n\n        Trial 4: 180.0 ms...\nTrial 1: 180.0 ms...\n\n        Trial 2: 190.0 ms...\nTrial 3: 190.0 ms...\n\n        Trial 4: 190.0 ms...\nTrial 1: 190.0 ms...\n\n        Trial 2: 200.0 ms...\n\n        Trial 3: 200.0 ms...\n\n        Trial 4: 200.0 ms...\nTrial 1: 200.0 ms...\n\n        Building the NEURON model\n\n        Building the NEURON model\n\n        [Done]\nTrial 5: 0.03 ms...\n\n        [Done]\nTrial 6: 0.03 ms...\n\n        Trial 5: 10.0 ms...\n\n        Trial 6: 10.0 ms...\n\n        Trial 5: 20.0 ms...\n\n        Trial 6: 20.0 ms...\n\n        Trial 5: 30.0 ms...\n\n        Trial 6: 30.0 ms...\n\n        Trial 5: 40.0 ms...\n\n        Trial 6: 40.0 ms...\n\n        Trial 5: 50.0 ms...\n\n        Trial 6: 50.0 ms...\n\n        Trial 5: 60.0 ms...\n\n        Trial 6: 60.0 ms...\n\n        Trial 5: 70.0 ms...\n\n        Trial 6: 70.0 ms...\n\n        Trial 5: 80.0 ms...\n\n        Trial 6: 80.0 ms...\n\n        Trial 5: 90.0 ms...\n\n        Trial 6: 90.0 ms...\n\n        Trial 5: 100.0 ms...\n\n        Trial 6: 100.0 ms...\n\n        Trial 5: 110.0 ms...\n\n        Trial 6: 110.0 ms...\n\n        Trial 5: 120.0 ms...\n\n        Trial 6: 120.0 ms...\n\n        Trial 5: 130.0 ms...\n\n        Trial 6: 130.0 ms...\n\n        Trial 5: 140.0 ms...\n\n        Trial 6: 140.0 ms...\n\n        Trial 5: 150.0 ms...\n\n        Trial 6: 150.0 ms...\n\n        Trial 5: 160.0 ms...\n\n        Trial 6: 160.0 ms...\nTrial 5: 170.0 ms...\n\n        Trial 6: 170.0 ms...\nTrial 5: 180.0 ms...\n\n        Trial 6: 180.0 ms...\nTrial 5: 190.0 ms...\n\n        Trial 6: 190.0 ms...\nTrial 5: 200.0 ms...\n\n        Trial 6: 200.0 ms...\n\n    </div>\n</div>\n<div class='code-cell'>\n    <code class='language-python'>\n        plot_dipole(dpls, show=False)\nplt.show()\n    </code>\n</div>\n<div class='output-cell'><div class='output-label'>\n    Out:\n</div>\n    <div class='output-code'>\n        &lt;Figure size 640x480 with 1 Axes&gt;\n    </div>\n</div>\n<div class='output-cell'>\n    <img src='output_nb_parallelism_joblib_notebook/fig_01.png'/>\n</div>"
        }
    }
}